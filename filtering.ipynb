{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from joblib import delayed, Parallel\n",
    "from surprise import Dataset, KNNBasic, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection.validation import fit_and_score, print_summary\n",
    "\n",
    "movies100k = pd.read_csv('./ml100k.u.item', names=['movie_id', 'movie_title', 'release_date', 'video_release_date', 'imdb_url'], delimiter='|', engine='python',encoding = \"latin-1\", usecols=range(5))\n",
    "movies1m = pd.read_csv('./ml1m.movies.dat', names=['movie_id', 'movie_title', 'ratings'], delimiter='::', engine='python',encoding = \"latin-1\")\n",
    "\n",
    "data100k = Dataset.load_builtin('ml-100k')\n",
    "data1m = Dataset.load_builtin('ml-1m')\n",
    "\n",
    "data_training, data_testing = train_test_split(data100k, random_state=22020, train_size=0.80)\n",
    "data_big_training, data_big_testing = train_test_split(data1m, random_state=22020, train_size=0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util functions.\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def getTopNRecommendations(predictions, n=5):\n",
    "    # code from https://surprise.readthedocs.io/en/stable/FAQ.html#how-to-get-the-top-n-recommendations-for-each-user\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    \"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "def getTopRecommendationsByUserId(predictions, userId, is1m=False, n=5):\n",
    "    top_n = getTopNRecommendations(predictions, n)\n",
    "    userRating = top_n.get(userId)\n",
    "    \n",
    "    it = 1\n",
    "    for iid, rating in userRating:\n",
    "        if is1m:\n",
    "            movieTitle = movies100k.loc[movies100k['movie_id'] == int(iid)]['movie_title']\n",
    "        else:\n",
    "            movieTitle = movies1m.loc[movies1m['movie_id'] == int(iid)]['movie_title']\n",
    "        print()\n",
    "        print(str(it) + \". \" + movieTitle.values + \", Rating: \" + str(round(rating, 2)))\n",
    "        it+=1\n",
    "\n",
    "def runAlgo(algorithm, data, measures):\n",
    "    data_training, data_testing = train_test_split(data, random_state=22020, train_size=0.80)\n",
    "    return fit_and_score(algorithm, data_training, data_testing, measures, True)\n",
    "\n",
    "def customCrossValidate(algorithm, data):\n",
    "    # manches wurde hier aus der Surprise-Library-Methode \"cross_validate\" verwendet. diese funktion wurde angepasst, da nicht mit Folds gearbeitet werden sollte.\n",
    "    measures = [m.lower() for m in ['MSE']]\n",
    "\n",
    "    delayed_list = (\n",
    "        delayed(runAlgo)(algorithm, data, measures)\n",
    "        for i in range(5)\n",
    "    )\n",
    "\n",
    "    out = Parallel(n_jobs=-1,pre_dispatch='2*n_jobs')(delayed_list)\n",
    "    (test_measures_dicts, train_measures_dicts, fit_times, test_times) = zip(*out)\n",
    "\n",
    "    test_measures = defaultdict(dict)\n",
    "    train_measures = defaultdict(dict)\n",
    "    \n",
    "    for m in measures:\n",
    "        test_measures[m] = np.asarray([d[m] for d in test_measures_dicts])\n",
    "        train_measures[m] = np.asarray([d[m] for d in train_measures_dicts])\n",
    "\n",
    "    print_summary(algorithm, measures, test_measures, train_measures, fit_times, test_times, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movielens 100k\n",
    "## User Based CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "user: 22         item: 20         r_ui = None   est = 3.56   {'actual_k': 40, 'was_impossible': False}\n",
      "\n",
      "['1. Silence of the Palace, The (Saimt el Qusur) (1994), Rating: 4.55']\n",
      "\n",
      "['2. Superweib, Das (1996), Rating: 4.16']\n",
      "\n",
      "['3. Nick of Time (1995), Rating: 4.11']\n",
      "\n",
      "['4. Destiny Turns on the Radio (1995), Rating: 4.07']\n",
      "\n",
      "[\"5. White Man's Burden (1995), Rating: 4.06\"]\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Evaluating MSE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "MSE (testset)     1.0258  1.0258  1.0258  1.0258  1.0258  1.0258  0.0000  \n",
      "MSE (trainset)    0.5706  0.5706  0.5706  0.5706  0.5706  0.5706  0.0000  \n",
      "Fit time          0.25    0.26    0.25    0.31    0.29    0.27    0.03    \n",
      "Test time         1.18    1.16    1.09    1.07    1.05    1.11    0.05    \n"
     ]
    }
   ],
   "source": [
    "# Predict Rating for UserID 20, Movie Id\n",
    "userId = 22\n",
    "movieId = 20\n",
    "\n",
    "userBasedAlgorithm = KNNBasic(sim_options={'name':'pearson', 'user_based':True})\n",
    "\n",
    "def userBasedFiltering(dataTraining, dataTesting, is1m=False):\n",
    "    algorithm = userBasedAlgorithm\n",
    "    predictions = algorithm.fit(dataTraining).test(dataTesting)\n",
    "    \n",
    "    if dataTraining.knows_user(userId) & dataTraining.knows_item(movieId):\n",
    "        algorithm.predict(str(userId), str(movieId), verbose=True)\n",
    "    else:\n",
    "        if dataTraining.knows_user(userId) == False:\n",
    "            unknownId = \"userId\"\n",
    "        else:\n",
    "            unknownId = \"movieId\"\n",
    "        print(unknownId + \" ist unbekannt. Andere ID wählen.\")\n",
    "\n",
    "    top_n = getTopNRecommendations(predictions, n=5)\n",
    "\n",
    "    userRecommendations = getTopRecommendationsByUserId(predictions, str(userId), is1m)\n",
    "\n",
    "userBasedFiltering(data_training, data_testing)\n",
    "\n",
    "customCrossValidate(userBasedAlgorithm, data100k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item-Based CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "user: 22         item: 20         r_ui = None   est = 3.80   {'actual_k': 40, 'was_impossible': False}\n",
      "\n",
      "['1. Under Siege 2: Dark Territory (1995), Rating: 4.2']\n",
      "\n",
      "['2. Silence of the Palace, The (Saimt el Qusur) (1994), Rating: 4.2']\n",
      "\n",
      "['3. Nick of Time (1995), Rating: 4.15']\n",
      "\n",
      "['4. Destiny Turns on the Radio (1995), Rating: 4.13']\n",
      "\n",
      "['5. Batman Forever (1995), Rating: 4.12']\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Evaluating MSE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "MSE (testset)     1.0626  1.0626  1.0626  1.0626  1.0626  1.0626  0.0000  \n",
      "MSE (trainset)    0.8048  0.8048  0.8048  0.8048  0.8048  0.8048  0.0000  \n",
      "Fit time          0.28    0.28    0.28    0.28    0.25    0.28    0.01    \n",
      "Test time         1.24    1.24    1.23    1.21    1.20    1.23    0.02    \n"
     ]
    }
   ],
   "source": [
    "itemBasedAlgorithm = KNNBasic(sim_options={'name':\"cosine\", 'user_based':False})\n",
    "def itemBasedFiltering(dataTraining, dataTesting, is1m=False):\n",
    "\n",
    "    algorithm = itemBasedAlgorithm\n",
    "    predictions = algorithm.fit(dataTraining).test(dataTesting)\n",
    "    \n",
    "    algorithm.predict(str(userId), str(movieId), verbose=True)\n",
    "\n",
    "    getTopRecommendationsByUserId(predictions, str(userId), is1m)\n",
    "\n",
    "itemBasedFiltering(data_training, data_testing)\n",
    "customCrossValidate(itemBasedAlgorithm, data100k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 22         item: 20         r_ui = None   est = 3.41   {'was_impossible': False}\n",
      "The top recommendations are: \n",
      "\n",
      "['1. Nick of Time (1995), Rating: 4.7']\n",
      "\n",
      "['2. Silence of the Palace, The (Saimt el Qusur) (1994), Rating: 4.23']\n",
      "\n",
      "['3. Superweib, Das (1996), Rating: 4.18']\n",
      "\n",
      "['4. Wild Bill (1995), Rating: 4.09']\n",
      "\n",
      "[\"5. White Man's Burden (1995), Rating: 4.07\"]\n",
      "Evaluating MSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "MSE (testset)     0.8784  0.8813  0.8799  0.8838  0.8767  0.8800  0.0024  \n",
      "MSE (trainset)    0.4696  0.4717  0.4682  0.4718  0.4705  0.4703  0.0013  \n",
      "Fit time          0.47    0.46    0.46    0.46    0.46    0.46    0.01    \n",
      "Test time         0.05    0.05    0.05    0.05    0.05    0.05    0.00    \n"
     ]
    }
   ],
   "source": [
    "svdBasedAlgorithm = SVD()\n",
    "def svdBasedFiltering(dataTraining, dataTesting, is1m=False):\n",
    "    algo = svdBasedAlgorithm\n",
    "    predictions = algo.fit(dataTraining).test(dataTesting)\n",
    "    \n",
    "    algo.predict(str(userId), str(movieId), verbose=True)\n",
    "        \n",
    "    print(\"The top recommendations are: \")\n",
    "    getTopRecommendationsByUserId(predictions, str(userId), is1m)\n",
    "\n",
    "svdBasedFiltering(data_training, data_testing)\n",
    "customCrossValidate(svdBasedAlgorithm, data100k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movielens 1M\n",
    "## User-Based CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "user: 22         item: 20         r_ui = None   est = 2.09   {'actual_k': 40, 'was_impossible': False}\n",
      "\n",
      "['1. Half Baked (1998), Rating: 4.64']\n",
      "\n",
      "[]\n",
      "\n",
      "['3. Kim (1950), Rating: 4.3']\n",
      "\n",
      "['4. Wild Bunch, The (1969), Rating: 4.28']\n",
      "\n",
      "['5. Celestial Clockwork (1994), Rating: 4.17']\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Evaluating MSE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "MSE (testset)     0.9223  0.9223  0.9223  0.9223  0.9223  0.9223  0.0000  \n",
      "MSE (trainset)    0.5154  0.5154  0.5154  0.5154  0.5154  0.5154  0.0000  \n",
      "Fit time          121.91  125.16  124.70  123.40  121.64  123.36  1.42    \n",
      "Test time         56.07   52.13   52.06   52.17   55.58   53.60   1.82    \n"
     ]
    }
   ],
   "source": [
    "userBasedFiltering(data_big_training, data_big_testing, True)\n",
    "customCrossValidate(userBasedAlgorithm, data1m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item-Based CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "user: 22         item: 20         r_ui = None   est = 2.75   {'actual_k': 40, 'was_impossible': False}\n",
      "\n",
      "[]\n",
      "\n",
      "['2. Spellbound (1945), Rating: 3.78']\n",
      "\n",
      "['3. Bride of Frankenstein (1935), Rating: 3.7']\n",
      "\n",
      "['4. Swept from the Sea (1997), Rating: 3.7']\n",
      "\n",
      "[]\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Evaluating MSE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "MSE (testset)     0.9957  0.9957  0.9957  0.9957  0.9957  0.9957  0.0000  \n",
      "MSE (trainset)    0.8108  0.8108  0.8108  0.8108  0.8108  0.8108  0.0000  \n",
      "Fit time          7.06    7.15    7.44    7.24    6.91    7.16    0.18    \n",
      "Test time         24.63   19.14   20.57   18.81   18.51   20.33   2.26    \n"
     ]
    }
   ],
   "source": [
    "itemBasedFiltering(data_big_training, data_big_testing, True)\n",
    "customCrossValidate(itemBasedAlgorithm, data1m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD Based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 22         item: 20         r_ui = None   est = 1.74   {'was_impossible': False}\n",
      "The top recommendations are: \n",
      "\n",
      "[]\n",
      "\n",
      "['2. Kim (1950), Rating: 4.18']\n",
      "\n",
      "['3. Bride of Frankenstein (1935), Rating: 3.93']\n",
      "\n",
      "['4. Celestial Clockwork (1994), Rating: 3.89']\n",
      "\n",
      "[]\n",
      "Evaluating MSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "MSE (testset)     0.7632  0.7618  0.7619  0.7619  0.7608  0.7619  0.0007  \n",
      "MSE (trainset)    0.4496  0.4482  0.4460  0.4505  0.4488  0.4486  0.0015  \n",
      "Fit time          4.12    4.52    4.32    4.25    4.23    4.29    0.13    \n",
      "Test time         0.82    0.74    0.83    0.82    0.79    0.80    0.03    \n"
     ]
    }
   ],
   "source": [
    "svdBasedFiltering(data_big_training, data_big_testing, True)\n",
    "customCrossValidate(svdBasedAlgorithm, data1m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ergebnisse\n",
    "\n",
    "> Anzumerken ist: bei den \"Folds\" in der Ausgabe handelt es sich nicht um Folds, sondern lediglich um die Iterationen. die \"Folds\"-Ausgabe ergibt sich aus der ``print_summary``-Methode, die ich aus der Library verwendet habe.\n",
    "\n",
    "Als Algorithmen habe ich:\n",
    "* einen Userbased k-Next Neighbors Algorithmus mit Pearson Correlation,\n",
    "* einen Itembased k-Next Neighbors Algorithmus mit Cosine Correlation,\n",
    "* sowie den SVD-Algorithmus.\n",
    "\n",
    "In Hinblick auf die durchschnittliche Wirksamkeit (Effectiveness) in Bezug auf den **Mean Squared Error** ergibt sich folgendes (gereiht von bester nach schlechtester) - gemessen am großen Datensatz (1m):\n",
    "\n",
    "1. **Item Based:**   0.9957 / 0.8108\n",
    "2. **User Based:**   0.9223 / 0.5154\n",
    "3. **SVD:**          0.7622 / 0.4493\n",
    "\n",
    "In Hinblick auf die durchschnittliche Effizienz ergibt sich die folgende Reihung (ebenso am größeren Datensatz gemessen, um Rauschen zu vermeiden):\n",
    "\n",
    "1. SVD:             Fit:   4.29s     -     Test:  0.80s\n",
    "2. Item Based:      Fit:   7.16s     -     Test: 20.33s\n",
    "3. User Based:      Fit: 123.36s     -     Test: 53.60s\n",
    "\n",
    "Somit ergibt sich, dass SVD im Vergleich zu den anderen beiden Algorithmen ungenau ist und weniger effektiv, allerdingst perfort er sehr gut, auch bei großen Datenmengen.\n",
    "\n",
    "Der Userbased Algorithmus dauert am längsten, erzielt aber auch bessere Ergebnisse.\n",
    "\n",
    "Der Item Based Algorithmus zeigt sehr geringe Abweichungen bei den erwarteten Ergebnissen von den echten Ergebnissen, und braucht im Fitting nur etwas länger als SVD, allerdings sehr viel länger beim Testen der Ergebnisse.\n",
    "\n",
    "---\n",
    "\n",
    "Die besten Ergebnisse erzielt wohl eine Mischung aus User based und item based Algorithmus. Hier kann man wahrscheinlich die Efficiency sowie Effectiveness optimieren. SVD wird wohl eine gute Methode sein, um halbwegs gute Vorhersagen zu machen, allerdings kann man sich nicht zu sehr auf die Daten verlassen.\n",
    "\n",
    "> Ich habe zusätzlich eine Funktion aus den Examples der Surprise-Library eingebaut, der zusätzlich die Recommendations ausgibt. Bei den Algorithmen werden unterschiedliche Recommendations gefunden, was allerdings interesstant ist, ist dass beim kleinen (100k) Datensatz in jedem Algorithmus \"Silence of the Palace\" gefunden wird. Das könnte allerdings damit zu tun haben, dass der Film sehr populär ist, und diese Popularität im Algorithmus nicht berücksichtigt wird."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
