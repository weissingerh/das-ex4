{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from joblib import delayed, Parallel\n",
    "from surprise import Dataset, KNNBasic, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection.validation import fit_and_score, print_summary\n",
    "\n",
    "movies = pd.read_csv('./ml-100k/u.item', names=['movie_id', 'movie_title', 'release_date', 'video_release_date', 'imdb_url'], delimiter='|', engine='python',encoding = \"latin-1\", usecols=range(5))\n",
    "\n",
    "data100k = Dataset.load_builtin('ml-100k')\n",
    "data1m = Dataset.load_builtin('ml-1m')\n",
    "\n",
    "data_training, data_testing = train_test_split(data100k, random_state=22020, train_size=0.80)\n",
    "data_big_training, data_big_testing = train_test_split(data1m, random_state=22020, train_size=0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util functions.\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def getTopNRecommendations(predictions, n=10):\n",
    "    # code from https://surprise.readthedocs.io/en/stable/FAQ.html#how-to-get-the-top-n-recommendations-for-each-user\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    \"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "def getTopRecommendationsByUserId(predictions, userId, n=10):\n",
    "    top_n = getTopNRecommendations(predictions, n)\n",
    "    userRating = top_n.get(userId)\n",
    "    \n",
    "    it = 1\n",
    "    for iid, rating in userRating:\n",
    "        movieTitle = movies.loc[movies['movie_id'] == int(iid)]['movie_title']\n",
    "        print()\n",
    "        print(str(it) + \". \" + movieTitle + \" ,Rating: \" + str(round(rating, 2)))\n",
    "        print()\n",
    "        it+=1\n",
    "\n",
    "def runAlgo(algorithm, data, measures):\n",
    "    data_training, data_testing = train_test_split(data, random_state=22020, train_size=0.80)\n",
    "    return fit_and_score(algorithm, data_training, data_testing, measures, True)\n",
    "\n",
    "def customCrossValidate(algorithm, data):\n",
    "    # manches wurde hier aus der Library-Methode \"cross_validate\" verwendet. diese funktion wurde angepasst, da nicht mit Folds gearbeitet werden sollte.\n",
    "    measures = [m.lower() for m in ['MSE']]\n",
    "\n",
    "    delayed_list = (\n",
    "        delayed(runAlgo)(algorithm, data, measures)\n",
    "        for i in range(5)\n",
    "    )\n",
    "\n",
    "    out = Parallel(n_jobs=-1,pre_dispatch='2*n_jobs')(delayed_list)\n",
    "    (test_measures_dicts, train_measures_dicts, fit_times, test_times) = zip(*out)\n",
    "\n",
    "    test_measures = defaultdict(dict)\n",
    "    train_measures = defaultdict(dict)\n",
    "    \n",
    "    for m in measures:\n",
    "        test_measures[m] = np.asarray([d[m] for d in test_measures_dicts])\n",
    "        train_measures[m] = np.asarray([d[m] for d in train_measures_dicts])\n",
    "\n",
    "    print_summary(algorithm, measures, test_measures, train_measures, fit_times, test_times, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movielens 100k\n",
    "## User Based CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "user: 22         item: 20         r_ui = None   est = 3.39   {'actual_k': 40, 'was_impossible': False}\n",
      "\n",
      "171    1. Empire Strikes Back, The (1980)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 4.6\n",
      "\n",
      "\n",
      "126    2. Godfather, The (1972)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 4.32\n",
      "\n",
      "\n",
      "193    3. Sting, The (1973)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 4.16\n",
      "\n",
      "\n",
      "209    4. Indiana Jones and the Last Crusade (1989)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 4.12\n",
      "\n",
      "\n",
      "194    5. Terminator, The (1984)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 4.11\n",
      "\n",
      "\n",
      "237    6. Raising Arizona (1987)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 4.05\n",
      "\n",
      "\n",
      "522    7. Cool Hand Luke (1967)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 3.99\n",
      "\n",
      "\n",
      "78    8. Fugitive, The (1993)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 3.94\n",
      "\n",
      "\n",
      "180    9. Return of the Jedi (1983)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 3.94\n",
      "\n",
      "\n",
      "432    10. Heathers (1989)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 3.91\n",
      "\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Evaluating MSE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "MSE (testset)     1.0258  1.0258  1.0258  1.0258  1.0258  1.0258  0.0000  \n",
      "MSE (trainset)    0.5706  0.5706  0.5706  0.5706  0.5706  0.5706  0.0000  \n",
      "Fit time          0.24    0.29    0.28    0.24    0.21    0.25    0.03    \n",
      "Test time         1.19    1.17    1.13    1.12    1.13    1.15    0.03    \n"
     ]
    }
   ],
   "source": [
    "# Predict Rating for UserID 20, Movie Id\n",
    "userId = 22\n",
    "movieId = 20\n",
    "\n",
    "userBasedAlgorithm = KNNBasic(sim_options={'name':'pearson', 'user_based':True})\n",
    "\n",
    "def userBasedFiltering(dataTraining, dataTesting):\n",
    "    algorithm = userBasedAlgorithm\n",
    "    predictions = algorithm.fit(dataTraining).test(dataTesting)\n",
    "    \n",
    "    if dataTraining.knows_user(userId) & dataTraining.knows_item(movieId):\n",
    "        algorithm.predict(str(userId), str(movieId), verbose=True)\n",
    "    else:\n",
    "        if dataTraining.knows_user(userId) == False:\n",
    "            unknownId = \"userId\"\n",
    "        else:\n",
    "            unknownId = \"movieId\"\n",
    "        print(unknownId + \" ist unbekannt. Andere ID wählen.\")\n",
    "\n",
    "    top_n = getTopNRecommendations(predictions, n=10)\n",
    "\n",
    "    userRecommendations = getTopRecommendationsByUserId(predictions, str(userId))\n",
    "\n",
    "userBasedFiltering(data_training, data_testing)\n",
    "\n",
    "customCrossValidate(userBasedAlgorithm, data100k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item-Based CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "user: 22         item: 20         r_ui = None   est = 3.43   {'actual_k': 40, 'was_impossible': False}\n",
      "\n",
      "237    1. Raising Arizona (1987)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 4.2\n",
      "\n",
      "\n",
      "180    2. Return of the Jedi (1983)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 4.15\n",
      "\n",
      "\n",
      "209    3. Indiana Jones and the Last Crusade (1989)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 4.05\n",
      "\n",
      "\n",
      "171    4. Empire Strikes Back, The (1980)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 4.05\n",
      "\n",
      "\n",
      "78    5. Fugitive, The (1993)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 4.0\n",
      "\n",
      "\n",
      "126    6. Godfather, The (1972)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 3.95\n",
      "\n",
      "\n",
      "193    7. Sting, The (1973)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 3.95\n",
      "\n",
      "\n",
      "230    8. Batman Returns (1992)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 3.94\n",
      "\n",
      "\n",
      "152    9. Fish Called Wanda, A (1988)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 3.92\n",
      "\n",
      "\n",
      "432    10. Heathers (1989)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 3.91\n",
      "\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Evaluating MSE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "MSE (testset)     1.0626  1.0626  1.0626  1.0626  1.0626  1.0626  0.0000  \n",
      "MSE (trainset)    0.8048  0.8048  0.8048  0.8048  0.8048  0.8048  0.0000  \n",
      "Fit time          0.28    0.28    0.28    0.26    0.25    0.27    0.01    \n",
      "Test time         1.29    1.26    1.20    1.21    1.19    1.23    0.04    \n"
     ]
    }
   ],
   "source": [
    "itemBasedAlgorithm = KNNBasic(sim_options={'name':\"cosine\", 'user_based':False})\n",
    "def itemBasedFiltering(dataTraining, dataTesting):\n",
    "\n",
    "    algorithm = itemBasedAlgorithm\n",
    "    predictions = algorithm.fit(dataTraining).test(dataTesting)\n",
    "    \n",
    "    algorithm.predict(str(userId), str(movieId), verbose=True)\n",
    "\n",
    "    getTopRecommendationsByUserId(predictions, str(userId))\n",
    "\n",
    "itemBasedFiltering(data_training, data_testing)\n",
    "customCrossValidate(itemBasedAlgorithm, data100k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 22         item: 20         r_ui = None   est = 3.23   {'was_impossible': False}\n",
      "The top recommendations are: \n",
      "\n",
      "78    1. Fugitive, The (1993)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 4.36\n",
      "\n",
      "\n",
      "171    2. Empire Strikes Back, The (1980)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 4.32\n",
      "\n",
      "\n",
      "126    3. Godfather, The (1972)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 4.29\n",
      "\n",
      "\n",
      "180    4. Return of the Jedi (1983)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 4.23\n",
      "\n",
      "\n",
      "194    5. Terminator, The (1984)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 4.1\n",
      "\n",
      "\n",
      "152    6. Fish Called Wanda, A (1988)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 4.09\n",
      "\n",
      "\n",
      "209    7. Indiana Jones and the Last Crusade (1989)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 4.0\n",
      "\n",
      "\n",
      "429    8. Duck Soup (1933)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 3.89\n",
      "\n",
      "\n",
      "432    9. Heathers (1989)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 3.83\n",
      "\n",
      "\n",
      "193    10. Sting, The (1973)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 3.79\n",
      "\n",
      "Evaluating MSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "MSE (testset)     0.8787  0.8789  0.8801  0.8788  0.8822  0.8797  0.0013  \n",
      "MSE (trainset)    0.4679  0.4698  0.4676  0.4689  0.4698  0.4688  0.0009  \n",
      "Fit time          0.47    0.46    0.47    0.46    0.46    0.46    0.01    \n",
      "Test time         0.05    0.05    0.05    0.05    0.05    0.05    0.00    \n"
     ]
    }
   ],
   "source": [
    "svdBasedAlgorithm = SVD()\n",
    "def svdBasedFiltering(dataTraining, dataTesting):\n",
    "    algo = svdBasedAlgorithm\n",
    "    predictions = algo.fit(dataTraining).test(dataTesting)\n",
    "    \n",
    "    algo.predict(str(userId), str(movieId), verbose=True)\n",
    "        \n",
    "    print(\"The top recommendations are: \")\n",
    "    getTopRecommendationsByUserId(predictions, str(userId))\n",
    "\n",
    "svdBasedFiltering(data_training, data_testing)\n",
    "customCrossValidate(svdBasedAlgorithm, data100k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movielens 1M\n",
    "## User-Based CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "user: 22         item: 20         r_ui = None   est = 2.07   {'actual_k': 40, 'was_impossible': False}\n",
      "\n",
      "857    1. Amityville: Dollhouse (1996)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 4.5\n",
      "\n",
      "\n",
      "918    2. City of Lost Children, The (1995)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 4.44\n",
      "\n",
      "\n",
      "Series([], Name: movie_title, dtype: object)\n",
      "Rating: 4.41\n",
      "\n",
      "\n",
      "1135    4. Ghosts of Mississippi (1996)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 4.32\n",
      "\n",
      "\n",
      "554    5. White Man's Burden (1995)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 4.19\n",
      "\n",
      "\n",
      "46    6. Ed Wood (1994)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 4.18\n",
      "\n",
      "\n",
      "109    7. Operation Dumbo Drop (1995)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 4.15\n",
      "\n",
      "\n",
      "Series([], Name: movie_title, dtype: object)\n",
      "Rating: 4.12\n",
      "\n",
      "\n",
      "1290    9. Celtic Pride (1996)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 4.06\n",
      "\n",
      "\n",
      "1357    10. The Deadly Cure (1996)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 4.04\n",
      "\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Evaluating MSE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "MSE (testset)     0.9223  0.9223  0.9223  0.9223  0.9223  0.9223  0.0000  \n",
      "MSE (trainset)    0.5154  0.5154  0.5154  0.5154  0.5154  0.5154  0.0000  \n",
      "Fit time          199.26  203.21  202.44  199.90  196.58  200.28  2.37    \n",
      "Test time         49.88   52.00   47.70   47.11   51.29   49.59   1.92    \n"
     ]
    }
   ],
   "source": [
    "userBasedFiltering(data_big_training, data_big_testing)\n",
    "customCrossValidate(userBasedAlgorithm, data1m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item-Based CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "user: 22         item: 20         r_ui = None   est = 2.61   {'actual_k': 40, 'was_impossible': False}\n",
      "\n",
      "222    1. Sling Blade (1996)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 3.85\n",
      "\n",
      "\n",
      "Series([], Name: movie_title, dtype: object)\n",
      "Rating: 3.85\n",
      "\n",
      "\n",
      "857    3. Amityville: Dollhouse (1996)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 3.82\n",
      "\n",
      "\n",
      "Series([], Name: movie_title, dtype: object)\n",
      "Rating: 3.8\n",
      "\n",
      "\n",
      "Series([], Name: movie_title, dtype: object)\n",
      "Rating: 3.8\n",
      "\n",
      "\n",
      "1135    6. Ghosts of Mississippi (1996)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 3.8\n",
      "\n",
      "\n",
      "Series([], Name: movie_title, dtype: object)\n",
      "Rating: 3.78\n",
      "\n",
      "\n",
      "1672    8. Mirage (1995)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 3.78\n",
      "\n",
      "\n",
      "1357    9. The Deadly Cure (1996)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 3.75\n",
      "\n",
      "\n",
      "554    10. White Man's Burden (1995)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 3.73\n",
      "\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Evaluating MSE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "MSE (testset)     0.9957  0.9957  0.9957  0.9957  0.9957  0.9957  0.0000  \n",
      "MSE (trainset)    0.8108  0.8108  0.8108  0.8108  0.8108  0.8108  0.0000  \n",
      "Fit time          6.96    7.61    7.57    7.60    7.22    7.39    0.26    \n",
      "Test time         19.78   22.92   19.37   19.15   19.37   20.12   1.42    \n"
     ]
    }
   ],
   "source": [
    "itemBasedFiltering(data_big_training, data_big_testing)\n",
    "customCrossValidate(itemBasedAlgorithm, data1m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD Based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 22         item: 20         r_ui = None   est = 1.85   {'was_impossible': False}\n",
      "The top recommendations are: \n",
      "\n",
      "1135    1. Ghosts of Mississippi (1996)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 4.18\n",
      "\n",
      "\n",
      "46    2. Ed Wood (1994)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 4.1\n",
      "\n",
      "\n",
      "Series([], Name: movie_title, dtype: object)\n",
      "Rating: 4.09\n",
      "\n",
      "\n",
      "1672    4. Mirage (1995)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 4.06\n",
      "\n",
      "\n",
      "Series([], Name: movie_title, dtype: object)\n",
      "Rating: 4.05\n",
      "\n",
      "\n",
      "Series([], Name: movie_title, dtype: object)\n",
      "Rating: 4.05\n",
      "\n",
      "\n",
      "222    7. Sling Blade (1996)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 3.99\n",
      "\n",
      "\n",
      "Series([], Name: movie_title, dtype: object)\n",
      "Rating: 3.97\n",
      "\n",
      "\n",
      "1357    9. The Deadly Cure (1996)\n",
      "Name: movie_title, dtype: object\n",
      "Rating: 3.96\n",
      "\n",
      "\n",
      "Series([], Name: movie_title, dtype: object)\n",
      "Rating: 3.87\n",
      "\n",
      "Evaluating MSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "MSE (testset)     0.7617  0.7634  0.7627  0.7621  0.7611  0.7622  0.0008  \n",
      "MSE (trainset)    0.4492  0.4487  0.4507  0.4484  0.4495  0.4493  0.0008  \n",
      "Fit time          4.91    4.30    4.28    4.29    4.56    4.47    0.24    \n",
      "Test time         0.73    0.87    0.76    0.67    0.62    0.73    0.09    \n"
     ]
    }
   ],
   "source": [
    "svdBasedFiltering(data_big_training, data_big_testing)\n",
    "customCrossValidate(svdBasedAlgorithm, data1m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ergebnisse\n",
    "\n",
    "> Anzumerken ist: bei den \"Folds\" in der Ausgabe handelt es sich nicht um Folds, sondern lediglich um die Iterationen. die \"Folds\"-Ausgabe ergibt sich aus der ``print_summary``-Methode, die ich aus der Library verwendet habe.\n",
    "\n",
    "Als Algorithmen habe ich:\n",
    "* einen Userbased k-Next Neighbors Algorithmus mit Pearson Correlation,\n",
    "* einen Itembased k-Next Neighbors Algorithmus mit Cosine Correlation,\n",
    "* sowie den SVD-Algorithmus.\n",
    "\n",
    "In Hinblick auf die durchschnittliche Wirksamkeit (Effectiveness) in Bezug auf den **Mean Squared Error** ergibt sich folgendes (gereiht von bester nach schlechtester) - gemessen am großen Datensatz (1m):\n",
    "\n",
    "1. **Item Based:**   0.9957 / 0.8108\n",
    "2. **User Based:**   0.9223 / 0.5154\n",
    "3. **SVD:**          0.7622 / 0.4493\n",
    "\n",
    "In Hinblick auf die durchschnittliche Effizienz ergibt sich die folgende Reihung (ebenso am größeren Datensatz gemessen, um Rauschen zu vermeiden):\n",
    "\n",
    "1. SVD:             Fit:  4.47s     -       Test:  0.73s\n",
    "2. Item Based:      Fit:  7.39s     -       Test: 20.12s\n",
    "3. User Based:      Fit: 200.28s     -       Test: 49.59s\n",
    "\n",
    "Somit ergibt sich, dass SVD im Vergleich zu den anderen beiden Algorithmen ungenau ist und weniger effektiv, allerdingst perfort er sehr gut, auch bei großen Datenmengen.\n",
    "\n",
    "Der Userbased Algorithmus dauert am längsten, erzielt aber auch bessere Ergebnisse.\n",
    "\n",
    "Der Item Based Algorithmus zeigt sehr geringe Abweichungen bei den erwarteten Ergebnissen von den echten Ergebnissen, und braucht im Fitting nur etwas länger als SVD, allerdings sehr viel länger beim Testen der Ergebnisse.\n",
    "\n",
    "---\n",
    "\n",
    "Die besten Ergebnisse erzielt wohl eine Mischung aus User based und item based Algorithmus. Hier kann man wahrscheinlich die Efficiency sowie Effectiveness optimieren. SVD wird wohl eine gute Methode sein, um halbwegs gute Vorhersagen zu machen, allerdings kann man sich nicht zu sehr auf die Daten verlassen.\n",
    "\n",
    "> Ich habe zusätzlich eine Funktion aus den Examples der Surprise-Library eingebaut, der zusätzlich die Recommendations ausgibt. Bei den Algorithmen werden unterschiedliche Recommendations gefunden, was allerdings interesstant ist, ist dass beim kleinen (100k) Datensatz in jedem Algorithmus \"The Godfather\" gefunden wird. Das könnte allerdings damit zu tun haben, dass der Film sehr populär ist, und diese Popularität im Algorithmus nicht berücksichtigt wird."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
